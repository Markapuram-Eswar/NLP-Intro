{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b273f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello everyone. let's learn NLP! let's start with the basics. \n",
    "I am running, jumping, and swimming in the beautiful garden. \n",
    "The cats are playing, dogs are barking, and birds are flying high above.\n",
    "I love reading books, writing stories, and learning new things every day.\n",
    "The students are studying, teachers are teaching, and parents are working hard.\n",
    "Beautiful flowers are blooming, trees are growing, and rivers are flowing peacefully.\n",
    "I enjoy walking, running, cycling, and hiking in the mountains.\n",
    "The children are playing, laughing, and having fun at the playground.\n",
    "I have been working, studying, and improving my skills continuously.\n",
    "The weather is changing, seasons are shifting, and nature is evolving.\n",
    "I love cooking, baking, and preparing delicious meals for my family.\n",
    "The artists are painting, musicians are playing, and dancers are performing gracefully.\n",
    "I enjoy traveling, exploring, and discovering new places around the world.\n",
    "The scientists are researching, experimenting, and discovering amazing things.\n",
    "I love gardening, planting, and watching my plants growing beautifully.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b646b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439a02af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.', \"let's learn NLP!\", \"let's start with the basics\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6e61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdfd71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " '.',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'learn',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232a6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f6e8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone.',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'learn',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6f9af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " 'let',\n",
       " 's',\n",
       " 'learn',\n",
       " 'NLP',\n",
       " 'let',\n",
       " 's',\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3227c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " '.',\n",
       " 'let',\n",
       " \"'\",\n",
       " 's',\n",
       " 'learn',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'let',\n",
       " \"'\",\n",
       " 's',\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "tokenizer.tokenize(corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90dcabe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " '.',\n",
       " \"let's\",\n",
       " 'learn',\n",
       " 'NLP',\n",
       " '!',\n",
       " \"let's\",\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f98787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.', \"let's learn NLP!\", \"let's start with the basics\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import PunktTokenizer\n",
    "tokenizer = PunktTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8f820c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone.',\n",
       " \"let's\",\n",
       " 'learn',\n",
       " 'NLP!',\n",
       " \"let's\",\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0890eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'everyone',\n",
       " '.',\n",
       " 'let',\n",
       " \"'\",\n",
       " 's',\n",
       " 'learn',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'let',\n",
       " \"'\",\n",
       " 's',\n",
       " 'start',\n",
       " 'with',\n",
       " 'the',\n",
       " 'basics']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Words = [\"apples\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802963a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292d277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
